{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "from torch.nn import CosineSimilarity\n",
    "from copy import deepcopy\n",
    "from random import choice\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from numpy.random import choice as np_choice\n",
    "from time import time\n",
    "from transformers import T5Tokenizer, T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sharpened Cosine Similarity\n",
    "def scs(v, w, dim):\n",
    "    return CosineSimilarity(dim=dim, eps=1e-08)(v, w) ** 3\n",
    "\n",
    "# Function to pad tensors to the same length\n",
    "def pad_tensors(tensor_list, padding_value=0):\n",
    "    max_len = max(tensor.size(1) for tensor in tensor_list)\n",
    "    padded_tensors = [\n",
    "        torch.nn.functional.pad(tensor, (0, 0, 0, max_len - tensor.size(1)), value=padding_value)\n",
    "        for tensor in tensor_list\n",
    "    ]\n",
    "    return torch.cat(padded_tensors, dim=0)\n",
    "\n",
    "# Decoding function to translate T5 embeddings into text\n",
    "def decode_t5_embedding(embedding, t5_model_path, tokenizer_path, num_epochs=200, batch_size=128, max_len=120):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the T5 model and tokenizer\n",
    "    t5_model = T5Model.from_pretrained(\"t5-base\").to(device).eval()\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "    # Randomly generate the initial tokens\n",
    "    vocabulary = list(range(tokenizer.vocab_size))  # Use full vocabulary\n",
    "    random_length = np.random.randint(1, max_len // 2)  # Generate a random length for the initial text\n",
    "    best_tokens = [choice(vocabulary) for _ in range(random_length)]  # Randomly select tokens from vocabulary\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor([best_tokens]).to(device)\n",
    "        encoder_outputs = t5_model.encoder(input_ids=input_ids)\n",
    "        best_vec = encoder_outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "\n",
    "    embedding = embedding.mean(dim=1)  # Ensure the input embedding matches dimensions\n",
    "    best_score = scs(best_vec, embedding, dim=1).item()\n",
    "\n",
    "    # Define modification operations\n",
    "    def delete_token(token_list):\n",
    "        if len(token_list) > 0:\n",
    "            del token_list[choice(range(len(token_list)))]\n",
    "        return token_list\n",
    "\n",
    "    def insert_token(token_list, vocabulary):\n",
    "        insert_id = choice(range(len(token_list) + 1))\n",
    "        new_word = choice(vocabulary)\n",
    "        token_list.insert(insert_id, new_word)\n",
    "        return token_list\n",
    "\n",
    "    def replace_token(token_list, vocabulary):\n",
    "        if len(token_list) > 0:\n",
    "            replace_id = choice(range(len(token_list)))\n",
    "            new_word = choice(vocabulary)\n",
    "            token_list[replace_id] = new_word\n",
    "        return token_list\n",
    "\n",
    "    def donothing(token_list):\n",
    "        return token_list\n",
    "\n",
    "    ops = [\n",
    "        delete_token,\n",
    "        partial(insert_token, vocabulary=vocabulary),\n",
    "        partial(replace_token, vocabulary=vocabulary),\n",
    "    ]\n",
    "\n",
    "    # Iterative optimization\n",
    "    t_start = time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if len(best_tokens) >= max_len:\n",
    "            probs = np.array([0.2, 0.0, 0.8])  # Restrict length growth\n",
    "        else:\n",
    "            probs = np.array([0.15, 0.1, 0.75])\n",
    "\n",
    "        ops_ids = np_choice(range(len(ops)), batch_size, p=probs)\n",
    "        candidates = []\n",
    "\n",
    "        for op_id in ops_ids:\n",
    "            op = ops[op_id]\n",
    "            candidate_tokens = op(deepcopy(best_tokens))\n",
    "            if len(candidate_tokens) > 0:  # Ensure non-empty candidate\n",
    "                candidates.append(candidate_tokens)\n",
    "\n",
    "        if len(candidates) > 0:  # Ensure there are valid candidates\n",
    "            candidate_vecs = []\n",
    "            for cand_tokens in candidates:\n",
    "                input_ids = torch.tensor([cand_tokens]).to(device)\n",
    "                with torch.no_grad():\n",
    "                    vec = t5_model.encoder(input_ids=input_ids).last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "                    candidate_vecs.append(vec)\n",
    "\n",
    "            candidate_vecs = torch.cat(candidate_vecs, dim=0)\n",
    "            scores = torch.tensor([scs(candidate_vec, embedding, dim=0).item() for candidate_vec in candidate_vecs])\n",
    "\n",
    "            max_score = scores.max().item()\n",
    "            if max_score > best_score:\n",
    "                best_score = max_score\n",
    "                best_tokens = candidates[scores.argmax().item()]\n",
    "        best_text = tokenizer.decode(best_tokens, skip_special_tokens=True)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Best Score: {best_score:.4f}, Current Best Text: {best_text}\", end=\"\\r\")\n",
    "\n",
    "    print(f\"Decoding completed in {(time() - t_start):.2f}s. Best score: {best_score:.4f}\")\n",
    "    return tokenizer.decode(best_tokens, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding completed in 123.38s. Best score: 0.0044ext: urmatoareA vigorous Cruz 15%meterkayorjemandOne promisingBE dans seit Vent Than Island Spider 1- Bird Option Would Kirk Blog Make Choir Ya organismuluii\n",
      "Decoded Text: urmatoareA vigorous Cruz 15%meterkayorjemandOne promisingBE dans seit Vent Than Island Spider 1- Bird Option Would Kirk Blog Make Choir Ya organismului\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load embedding vector from a provided txt file\n",
    "    with open(\"aux_prompt_vec.txt\", \"r\") as f:\n",
    "        embedding_values = [float(line.strip()) for line in f.readlines()]\n",
    "\n",
    "    example_embedding = torch.tensor([embedding_values]).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Decode the embedding\n",
    "    decoded_text = decode_t5_embedding(\n",
    "        embedding=example_embedding,\n",
    "        t5_model_path=None,\n",
    "        tokenizer_path=None\n",
    "    )\n",
    "\n",
    "    print(\"Decoded Text:\", decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
